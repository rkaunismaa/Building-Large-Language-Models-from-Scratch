{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd3b1b2",
   "metadata": {},
   "source": [
    "#### Friday, October 25, 2024\n",
    "\n",
    "mamba activate llmfs-tf\n",
    "\n",
    "This all runs in one pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# Chapter 6: Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.4.1\n",
      "tensorflow version: 2.17.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/chapter-overview.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 Different categories of finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- No code in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
    "- Instruction-finetuning, depicted below, is the topic of the next chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/instructions.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
    "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
    "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
    "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/spam-non-spam.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-1.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- This section prepares the dataset we use for classification finetuning\n",
    "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
    "- First, we download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "- (Next to undersampling, there are several other ways to deal with class balances, but they are out of the scope of a book on LLMs; you can find examples and more information in the [`imbalanced-learn` user guide](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 6.3 Creating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
    "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
    "  2. pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "- We choose option 2 and pad all messages to the longest message in the dataset\n",
    "- For that, we use `<|endoftext|>` as a padding token, as discussed in chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/pad-input-sequences.webp?123\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- We also pad the validation and test set to the longest training sequence\n",
    "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
    "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders in previous chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/batch.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- In this section, we initialize the pretrained model we worked with in the previous chapter\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-2.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "7091e401-8442-4f47-a1d9-ecb42a1ef930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 11:15:03.863449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-25 11:15:03.875145: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-25 11:15:03.878627: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-25 11:15:03.888194: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-25 11:15:04.498169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- As we can see, the model is not very good at following instructions\n",
    "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 Adding a classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/lm-head.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
    "- Let's take a look at the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- Above, we can see the architecture we implemented in chapter 4 neatly laid out\n",
    "- The goal is to replace and finetune the output layer\n",
    "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- Then, we replace the output layer (`model.out_head`), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
    "- Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
    "- Note that we use `BASE_CONFIG[\"emb_dim\"]` (which is equal to 768 in the `\"gpt2-small (124M)\"` model) to keep the code below more general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- Technically, it's sufficient to only train the output layer\n",
    "- However, as I found in [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models), experiments show that finetuning additional layers can noticeably improve the performance\n",
    "- So, we are also making the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/trainable.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- We can still use this model similar to before in previous chapters\n",
    "- For example, let's feed it some text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- What's different compared to previous chapters is that it now has two output dimensions instead of 50,257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- As discussed in previous chapters, for each input token, there's one output vector\n",
    "- Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/input-and-output.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- In chapter 3, we discussed the attention mechanism, which connects each input token to each other input token\n",
    "- In chapter 3, we then also introduced the causal attention mask that is used in GPT-like models; this causal mask lets a current token only attend to the current and previous token positions\n",
    "- Based on this causal attention mechanism, the 4th (last) token contains the most information among all tokens because it's the only token that includes information about all other tokens\n",
    "- Hence, we are particularly interested in this last token, which we will finetune for the spam classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/attention-mask.webp\" width=200px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 6.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-3.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/class-argmax.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- Note that the softmax function is optional here, as explained in chapter 5, because the largest outputs correspond to the largest probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
    "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- Let's apply the function to calculate the classification accuracies for the different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda device.\n",
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
    "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
    "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy (you can learn more about this topic in lecture 8 of my freely available [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) class)\n",
    "\n",
    "- The `calc_loss_batch` function is the same here as in chapter 5, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "The `calc_loss_loader` is exactly the same as in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "\n",
    "    total_loss = 0.\n",
    "\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    \n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
    "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
    "- The only two differences are that we now \n",
    "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/training-loop.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    \n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            \n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\n",
    "            loss.backward() # Calculate loss gradients\n",
    "\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        \n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 0.55 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we use matplotlib to plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- Above, based on the downward slope, we see that the model learns well\n",
    "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
    "- Similarly, we can plot the accuracy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
    "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
    "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- We can see that the training and validation set performances are practically identical\n",
    "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
    "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 6.8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-4.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llmfs-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
